# âš¡ SmartGridFlow: A Cloud-Native Real-Time Smart-Meter Data Pipeline

**SmartGridFlow** is a cloud-native, real-time data pipeline that simulates and processes energy-usage data from smart meters â€” mirroring production-grade systems used by energy and infrastructure providers. It showcases real-time streaming with **Kafka**, Python-based processing, and persistent storage in **PostgreSQL**, all orchestrated via **Kubernetes** and **Terraform**.

---

## ğŸ“ Architecture Diagram

```text
[ Smart Meter Simulator Pod ]
            |
 Kafka Topic: smart-meter-data
            |
   [ Kafka Consumer Pod ]
            |
     PostgreSQL Database
```

---

## ğŸš€ Tech Stack

- **Python** â€“ Simulator and consumer applications  
- **Apache Kafka** â€“ Real-time streaming platform  
- **PostgreSQL** â€“ Persistent storage for smart-meter readings  
- **Docker** â€“ Containerisation of all services  
- **Kubernetes (Kind)** â€“ Local Kubernetes cluster for development  
- **Terraform** â€“ Infrastructure-as-Code (deployed via Helm)  
- **Helm** â€“ Simplified deployment of Kafka and PostgreSQL  
- **Makefile** â€“ End-to-end automation of the pipeline  

---

## ğŸ“ Folder Structure

```text
smartgridflow/
â”œâ”€â”€ simulator/        # Smart-meter producer app
â”œâ”€â”€ consumer/         # Kafka consumer app
â”œâ”€â”€ terraform/        # Infrastructure provisioning (Kafka, Postgres)
â”œâ”€â”€ k8s/              # Kubernetes deployment YAMLs
â”‚   â”œâ”€â”€ producer/
â”‚   â””â”€â”€ consumer/
â”œâ”€â”€ kind-config.yaml  # Kind cluster configuration
â”œâ”€â”€ Makefile          # Automation commands
â””â”€â”€ README.md         # Project documentation
```

---

## âš™ï¸ How It Works

1. **Simulator** (Python) generates synthetic smart-meter readings and publishes them to the Kafka topic `smart-meter-data` every few seconds.  
2. **Kafka** receives and buffers these messages on the `smart-meter-data` topic.  
3. **Consumer** (Python) subscribes to the topic, processes incoming messages, and writes the results to **PostgreSQL**.  
4. **PostgreSQL** stores the data for downstream analysis and visualisation.  
5. All components run as pods in a **Kubernetes (Kind)** cluster, provisioned by **Terraform** and deployed via **Helm**.  

---

## ğŸ§ª Getting Started

### ğŸ”§ Prerequisites

Ensure the following are installed locally:

- Docker  
- Terraform  
- Kind (Kubernetes-in-Docker)  
- Python 3.10 +  
- Make  

---

### ğŸš€ Run Everything

```bash
make all
```

`make all` will:  

1. Provision the Kind cluster.  
2. Deploy Kafka and PostgreSQL with Terraform + Helm.  
3. Build Docker images for the simulator and consumer.  
4. Load the images into the cluster.  
5. Deploy the simulator and consumer apps.  
6. Tail logs and verify that PostgreSQL is receiving data.  

---

### ğŸ“¦ Makefile Commands

| Command         | Description                                                |
|-----------------|------------------------------------------------------------|
| `make all`      | Provision, build, deploy **and test** the entire pipeline  |
| `make apply`    | Run Terraform to set up infrastructure                     |
| `make build`    | Build Docker images and load them into the cluster         |
| `make deploy`   | Deploy simulator and consumer apps to Kubernetes           |
| `make test`     | Tail logs and confirm data is stored in PostgreSQL         |
| `make destroy`  | Tear down infrastructure and delete the Kind cluster       |

---

### ğŸ” Testing the Pipeline

```bash
make test
```

This will:  

- Stream logs from the simulator and consumer pods.  
- Confirm that data is being ingested into PostgreSQL.  
- Verify end-to-end pipeline functionality.  

---

### ğŸ§¼ Cleaning Up

```bash
make destroy
```

This command will:  

- Run `terraform destroy` to remove Kafka, PostgreSQL, and other resources.  
- Delete the Kind cluster entirely, returning your system to a clean state.  

---

## ğŸ¤ Contributing

Contributions are welcome! If youâ€™d like to suggest improvements, raise issues, or add features (e.g. Prometheus metrics, Grafana dashboards, CI/CD workflows), please open an issue or submit a pull request.

---

## ğŸ“„ Licence

Distributed under the **MIT Licence** â€” feel free to use, modify, and adapt this project as needed.
